import{_ as e,a}from"./chunks/gemm_gflops.D_GllyyK.js";import{_ as s,c as i,o as n,aA as l}from"./chunks/framework.CjAdrvu_.js";const r="/cuNumeric.jl/previews/PR51/assets/mc_eff.D50Jvsf_.svg",h="/cuNumeric.jl/previews/PR51/assets/mc_ops.CRKqJCSK.svg",o="/cuNumeric.jl/previews/PR51/assets/gs_gflops_diffeq.B5rjpaRc.svg",b=JSON.parse('{"title":"Benchmark Results","description":"","frontmatter":{},"headers":[],"relativePath":"benchmark_results.md","filePath":"benchmark_results.md","lastUpdated":null}'),d={name:"benchmark_results.md"};function c(p,t,k,g,u,m){return n(),i("div",null,t[0]||(t[0]=[l('<h1 id="Benchmark-Results" tabindex="-1">Benchmark Results <a class="header-anchor" href="#Benchmark-Results" aria-label="Permalink to &quot;Benchmark Results {#Benchmark-Results}&quot;">​</a></h1><p>For JuliaCon2025 we benchmarks cuNumeric.jl on 8 A100 GPUs (single-node) and compared it to the Python library cuPyNumeric and other relevant benchmarks depending on the problem. All results shown are weak scaling. We hope to have multi-node benchmarks soon!</p><ul><li><a href="./benchmark_results#Benchmark-Results">Benchmark Results</a><ul><li><a href="./benchmark_results#sgemm">SGEMM</a></li><li><a href="./benchmark_results#Monte-Carlo-Integration">Monte Carlo Integration</a></li><li><a href="./benchmark_results#Gray-Scott-(2D)">Gray Scott (2D)</a></li></ul></li></ul><h2 id="SGEMM" tabindex="-1">SGEMM <a class="header-anchor" href="#SGEMM" aria-label="Permalink to &quot;SGEMM {#SGEMM}&quot;">​</a></h2><p>Code Outline:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">mul!</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(C, A, B)</span></span></code></pre></div><table tabindex="0"><thead><tr><th style="text-align:center;">GEMM Efficiency</th><th style="text-align:center;">GEMM GFLOPS</th></tr></thead><tbody><tr><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;"><img src="'+e+'" alt=""></td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;"><img src="'+a+`" alt=""></td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;"></td><td style="text-align:center;"></td></tr></tbody></table><h2 id="Monte-Carlo-Integration" tabindex="-1">Monte-Carlo Integration <a class="header-anchor" href="#Monte-Carlo-Integration" aria-label="Permalink to &quot;Monte-Carlo Integration {#Monte-Carlo-Integration}&quot;">​</a></h2><p>Monte-Carlo integration is embaressingly parallel and should scale perfectly. We do not know the exact number of operations in <code>exp</code> so the GFLOPs is off by a constant factor.</p><p>Code Outline:</p><div class="language-julia vp-adaptive-theme"><button title="Copy Code" class="copy"></button><span class="lang">julia</span><pre class="shiki shiki-themes github-light github-dark vp-code" tabindex="0"><code><span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">integrand </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (x) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-&gt;</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> exp</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">-</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">square</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x))</span></span>
<span class="line"><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">val </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">=</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;"> (V</span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">/</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">N) </span><span style="--shiki-light:#D73A49;--shiki-dark:#F97583;">*</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;"> sum</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(</span><span style="--shiki-light:#005CC5;--shiki-dark:#79B8FF;">integrand</span><span style="--shiki-light:#24292E;--shiki-dark:#E1E4E8;">(x))</span></span></code></pre></div><table tabindex="0"><thead><tr><th style="text-align:center;">MC Efficiency</th><th style="text-align:center;">MC GFLOPS</th></tr></thead><tbody><tr><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;"><img src="`+r+'" alt=""></td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;"></td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;"><img src="'+h+'" alt=""></td><td style="text-align:center;"></td></tr><tr><td style="text-align:center;"></td><td style="text-align:center;"></td></tr></tbody></table><h2 id="Gray-Scott-2D" tabindex="-1">Gray-Scott (2D) <a class="header-anchor" href="#Gray-Scott-2D" aria-label="Permalink to &quot;Gray-Scott (2D) {#Gray-Scott-2D}&quot;">​</a></h2><p>Solving a PDE requires halo-exchanges and lots of data movement. In this benchmark we fall an order of magnitude short of the <code>ImplicitGlobalGrid.jl</code> library which specifically targets multi-node, multi-GPU halo exchanges. We attribute this to the lack of kernel fusion in cuNumeric.jl</p><p><img src="'+o+'" alt=""></p>',15)]))}const _=s(d,[["render",c]]);export{b as __pageData,_ as default};
